{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzGFQAUnH_-2",
        "outputId": "ad547583-75aa-4d05-e0db-599b711fe26e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3m_sWDBM6rW",
        "outputId": "1d777950-c399-479b-c401-3847c28572ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.47.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz_HTpHcBUEZ",
        "outputId": "9d614997-da62-41dd-e628-1470efce3abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/modeling_auto.py:2242: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reasoning:\n",
            "The user has indicated a desire to make a payment.\n",
            "\n",
            "To complete a payment, a method of payment is needed. This could be a credit card, cash, or another form of electronic payment.\n",
            "\n",
            "In the image, there is a credit card visible.\n",
            "\n",
            "Therefore, the optimal solution is to provide the credit card so the user can make the payment without inconvenience.\n",
            "\n",
            "Assistant’s response:\n",
            "I will give you the credit card.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "model_id = \"unsloth/Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit\"\n",
        "model = AutoModelForVision2Seq.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "# 안전한 토큰 설정\n",
        "eos_id = processor.tokenizer.eos_token_id\n",
        "im_end_id = processor.tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
        "stop_ids = [t for t in [eos_id, im_end_id] if t is not None]\n",
        "\n",
        "if model.generation_config.eos_token_id is None:\n",
        "    model.generation_config.eos_token_id = eos_id\n",
        "if model.generation_config.pad_token_id is None:\n",
        "    # Qwen 계열은 pad_token이 없을 수 있어 eos로 대체\n",
        "    model.generation_config.pad_token_id = eos_id\n",
        "\n",
        "def chat(messages, max_new_tokens=768, temperature=0.7, top_p=0.9):\n",
        "    # Qwen2.5 전용 템플릿\n",
        "    prompt = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # 이미지 로딩 (RGB 권장)\n",
        "    imgs = []\n",
        "    for msg in messages:\n",
        "        for c in msg[\"content\"]:\n",
        "            if c[\"type\"] == \"image\":\n",
        "                imgs.append(Image.open(c[\"image\"]).convert(\"RGB\"))\n",
        "\n",
        "    # 텐서화\n",
        "    inputs = processor(\n",
        "        text=prompt,\n",
        "        images=imgs if imgs else None,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "    # 생성\n",
        "    gen_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,          # 목록형 설명이 끊기지 않도록 샘플링 권장\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        eos_token_id=stop_ids,   # eos 혹은 <|im_end|> 도달 시 종료\n",
        "        pad_token_id=model.generation_config.pad_token_id\n",
        "    )\n",
        "\n",
        "    # \"생성된 부분만\" 디코드\n",
        "    new_tokens = gen_ids[0, input_len:]\n",
        "    text = processor.decode(new_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "    return text\n",
        "CoT = \"\"\"\n",
        "example 1)\n",
        "user : My touchpad is broken.\n",
        "\n",
        "Reasoning :\n",
        "The user stated the problem: \"My touchpad is broken.\"\n",
        "\n",
        "To operate the laptop, an alternative input device is required.\n",
        "\n",
        "The most appropriate substitute input device is a mouse.\n",
        "\n",
        "It is confirmed that a mouse is available nearby in image.\n",
        "\n",
        "Therefore, the optimal solution is to provide the user with the mouse so they can use the laptop without inconvenience.\n",
        "\n",
        "Assistant’s response:\n",
        "I will hand you the mouse.\n",
        "\n",
        "example 2)\n",
        "user : My phone battery is dead.\n",
        "\n",
        "Reasoning :\n",
        "The user stated the problem: \"My phone battery is dead.\"\n",
        "\n",
        "To use the phone, a power supply is required.\n",
        "\n",
        "When the battery is depleted, an alternative way to supply power is necessary.\n",
        "\n",
        "The appropriate alternatives are connecting a charger or using a power bank.\n",
        "\n",
        "A charger is visible in the image.\n",
        "\n",
        "Therefore, the optimal solution is to provide the charger so the user can use the phone without inconvenience.\n",
        "\n",
        "Assistant’s response:\n",
        "I will connect the charger for you.\n",
        "\n",
        "Generate a new answer following the examples format.\n",
        "\"\"\"\n",
        "\n",
        "# 첫 번째 질문 (이미지 + 텍스트)\n",
        "conversation = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [\n",
        "        {\"type\": \"image\", \"image\": \"/content/사진 5.png\"},\n",
        "        {\"type\":\"text\",\"text\": CoT},\n",
        "        {\"type\": \"text\", \"text\": \"I want to pay.\"}\n",
        "    ]\n",
        "}]\n",
        "\n",
        "print(chat(conversation))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 질문 (이미지 + 텍스트)\n",
        "conversation = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [\n",
        "        {\"type\": \"image\", \"image\": \"/content/사진 6.png\"},\n",
        "        {\"type\":\"text\",\"text\": CoT},\n",
        "        {\"type\": \"text\", \"text\": \"My mouth smells weird.\"}\n",
        "    ]\n",
        "}]\n",
        "\n",
        "print(chat(conversation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAL1NEYPE5o6",
        "outputId": "903e8aad-22d7-4c4c-f15d-93cec5b8c827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reasoning:\n",
            "The user has mentioned that their mouth smells weird. This issue typically indicates bad breath, which can be caused by various factors such as poor oral hygiene, food remnants, or underlying health issues.\n",
            "\n",
            "To address this problem, it's important to clean one's teeth thoroughly and consider using mouthwash or a breath freshener.\n",
            "\n",
            "Mouthwash and a toothbrush are visible in the image, suggesting these items might be used to address the issue.\n",
            "\n",
            "Therefore, the optimal solution is to suggest the user use the mouthwash or brush their teeth.\n",
            "\n",
            "Assistant’s response:\n",
            "I recommend brushing your teeth or using mouthwash to improve your breath.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}